# LR_Theroy

+ **逻辑回归问题说明**

有<img src="http://latex.codecogs.com/gif.latex?N" title="N" />个样本，<img src="http://latex.codecogs.com/gif.latex?(X_{i},&space;Y_{i}),&space;i\in&space;(1,2\cdots&space;N)" title="(X_{i}, Y_{i}), i\in (1,2\cdots N)" />，<img src="http://latex.codecogs.com/gif.latex?X_{i}&space;=&space;[X_{i}^{1},&space;X_{i}^{2},&space;\cdots&space;X_{i}^{m-1}]" title="X_{i} = [X_{i}^{1}, X_{i}^{2}, \cdots X_{i}^{m-1}]" />， 表示每个样本有<img src="http://latex.codecogs.com/gif.latex?m-1" title="m-1" />个特征；<a href="http://www.codecogs.com/eqnedit.php?latex=Y_{i}&space;=0\begin{matrix}&space;&&space;or&space;&&space;1&space;\end{matrix}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?Y_{i}&space;=0\begin{matrix}&space;&&space;or&space;&&space;1&space;\end{matrix}" title="Y_{i} =0\begin{matrix} & or & 1 \end{matrix}" /></a>。
 
现在为每个样本添加一个特征值为1的特征，也就是令<a href="http://www.codecogs.com/eqnedit.php?latex=X_{i}&space;=&space;[X_{i}^{1},X_{i}^{2},\cdots&space;X_{i}^{m-1},X_{i}^{m}]" target="_blank"><img src="http://latex.codecogs.com/gif.latex?X_{i}&space;=&space;[X_{i}^{1},X_{i}^{2},\cdots&space;X_{i}^{m-1},X_{i}^{m}]" title="X_{i} = [X_{i}^{1},X_{i}^{2},\cdots X_{i}^{m-1},X_{i}^{m}]" /></a>，其中<a href="http://www.codecogs.com/eqnedit.php?latex=X_{i}^{m}&space;=&space;1" target="_blank"><img src="http://latex.codecogs.com/gif.latex?X_{i}^{m}&space;=&space;1" title="X_{i}^{m} = 1" /></a>。

这样操作本质就是将<a href="http://www.codecogs.com/eqnedit.php?latex=w*X&space;&plus;&space;b" target="_blank"><img src="http://latex.codecogs.com/gif.latex?w*X&space;&plus;&space;b" title="w*X + b" /></a>中的<a href="http://www.codecogs.com/eqnedit.php?latex=w" target="_blank"><img src="http://latex.codecogs.com/gif.latex?w" title="w" /></a>和<a href="http://www.codecogs.com/eqnedit.php?latex=w" target="_blank"><img src="http://latex.codecogs.com/gif.latex?b" title="b" /></a>合为一个<a href="http://www.codecogs.com/eqnedit.php?latex=W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?W" title="W" /></a>，便于计算。

<a href="http://www.codecogs.com/eqnedit.php?latex=Sigmoid" target="_blank"><img src="http://latex.codecogs.com/gif.latex?Sigmoid" title="Sigmoid" /></a>函数表达式为：

<a href="http://www.codecogs.com/eqnedit.php?latex=\Phi(x)=\frac{1}{1&plus;e^{-x}}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Phi(x)=\frac{1}{1&plus;e^{-x}}" title="\Phi(x)=\frac{1}{1+e^{-x}}" /></a>

要使得到的<a href="http://www.codecogs.com/eqnedit.php?latex=W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?W" title="W" /></a>满足：

<a href="http://www.codecogs.com/eqnedit.php?latex=X_{i}\cdot&space;W&space;=\left\{\begin{matrix}&space;\geqslant&space;0&space;&&\mathrm{if}Y_{i}=1&space;\\&space;<&space;0&space;&&\mathrm{if}Y_{i}=0&space;\end{matrix}\right." target="_blank"><img src="http://latex.codecogs.com/gif.latex?X_{i}\cdot&space;W&space;=\left\{\begin{matrix}&space;\geqslant&space;0&space;&&\mathrm{if}Y_{i}=1&space;\\&space;<&space;0&space;&&\mathrm{if}Y_{i}=0&space;\end{matrix}\right." title="X_{i}\cdot W =\left\{\begin{matrix} \geqslant 0 &&\mathrm{if}Y_{i}=1 \\ < 0 &&\mathrm{if}Y_{i}=0 \end{matrix}\right." /></a>

也就是：

<a href="http://www.codecogs.com/eqnedit.php?latex=\Phi(X_{i}\cdot&space;W)&space;=&space;\begin{cases}&space;\geq&space;0.5&space;&&space;\text{&space;if&space;}&space;Y_{i}=1&space;\\&space;<&space;0.5&space;&&space;\text{&space;if&space;}&space;Y_{i}=0&space;\end{cases}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Phi(X_{i}\cdot&space;W)&space;=&space;\begin{cases}&space;\geq&space;0.5&space;&&space;\text{&space;if&space;}&space;Y_{i}=1&space;\\&space;<&space;0.5&space;&&space;\text{&space;if&space;}&space;Y_{i}=0&space;\end{cases}" title="\Phi(X_{i}\cdot W) = \begin{cases} \geq 0.5 & \text{ if } Y_{i}=1 \\ < 0.5 & \text{ if } Y_{i}=0 \end{cases}" /></a>

我们令

<a href="http://www.codecogs.com/eqnedit.php?latex=P(Y_{i}=1|X_{i},&space;W)=\Phi&space;(X_{i}\cdot&space;W)\\&space;P(Y_{i}=0|X_{i},&space;W)=1&space;-&space;\Phi&space;(X_{i}\cdot&space;W)\\" target="_blank"><img src="http://latex.codecogs.com/gif.latex?P(Y_{i}=1|X_{i},&space;W)=\Phi&space;(X_{i}\cdot&space;W)\\&space;P(Y_{i}=0|X_{i},&space;W)=1&space;-&space;\Phi&space;(X_{i}\cdot&space;W)\\" title="P(Y_{i}=1|X_{i}, W)=\Phi (X_{i}\cdot W)\\ P(Y_{i}=0|X_{i}, W)=1 - \Phi (X_{i}\cdot W)\\" /></a>

其中<a href="http://www.codecogs.com/eqnedit.php?latex=P(Y_{i}=1|X_{i},&space;W)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?P(Y_{i}=1|X_{i},&space;W)" title="P(Y_{i}=1|X_{i}, W)" /></a>表示对于给定的<a href="http://www.codecogs.com/eqnedit.php?latex=W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?W" title="W" /></a>和<a href="http://www.codecogs.com/eqnedit.php?latex=X_{i}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?X_{i}" title="X_{i}" /></a>， 得出的<a href="http://www.codecogs.com/eqnedit.php?latex=Y_{i}&space;=&space;1" target="_blank"><img src="http://latex.codecogs.com/gif.latex?Y_{i}&space;=&space;1" title="Y_{i} = 1" /></a>的概率。

将上面两个式子合在一起：

<a href="http://www.codecogs.com/eqnedit.php?latex=P(Y&space;=&space;Y_{i}|(X_{i},W))&space;=&space;\Phi&space;(X_{i}\cdot&space;W)^{Y_{i}}\times&space;(1-\Phi&space;(X_{i}\cdot&space;W)^{1-Y_{i}}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?P(Y&space;=&space;Y_{i}|(X_{i},W))&space;=&space;\Phi&space;(X_{i}\cdot&space;W)^{Y_{i}}\times&space;(1-\Phi&space;(X_{i}\cdot&space;W)^{1-Y_{i}}" title="P(Y = Y_{i}|(X_{i},W)) = \Phi (X_{i}\cdot W)^{Y_{i}}\times (1-\Phi (X_{i}\cdot W)^{1-Y_{i}}" /></a>

利用极大似然估计，也就是计算下式的最大值：

<img src="http://latex.codecogs.com/gif.latex?\mathbf{ML}(W)=&space;\prod_{i=1}^{N}P(Y=Y_{i}|X_{i},W)" title="\mathbf{ML}(W)= \prod_{i=1}^{N}P(Y=Y_{i}|X_{i},W)" />

上述式子和取对数后的式子增减性相同，下面取其对数：

<img src="http://latex.codecogs.com/gif.latex?\mathbf{L}(W)&space;=&space;\mathit{ln}(\mathbf{ML}(W))&space;\\&space;...............=&space;\mathit{ln}(\Phi(X_{1}\cdot&space;W)^{Y_{1}}\times&space;(1-&space;\Phi(X_{1}\cdot&space;W))^{1-Y_{1}}&space;\times&space;\cdots\\&space;...............\cdots&space;\times&space;\Phi(X_{N}\cdot&space;W)^{Y_{N}}\times&space;(1-&space;\Phi(X_{N}\cdot&space;W))^{1-Y_{N}})\\&space;\\&space;...............=&space;\mathit{ln}(\Phi(X_{1}\cdot&space;W)^{Y_{1}})&space;&plus;&space;\mathit{ln}((1-&space;\Phi(X_{1}\cdot&space;W))^{1-Y_{1}})&plus;\dots&space;\\&space;...............\cdots&space;&plus;&space;\mathit{ln}(\Phi(X_{N}\cdot&space;W)^{Y_{N}})&space;&plus;&space;\mathit{ln}((1-&space;\Phi(X_{N}\cdot&space;W))^{1-Y_{N}})\\&space;\\&space;...............=Y_{1}\mathit{ln}(\Theta&space;(X_{1}\cdot&space;W))&space;&plus;&space;(1&space;-&space;Y_{1})\mathit{ln}(1-\Theta&space;(X_{1}\cdot&space;W))&plus;\cdots&space;\\&space;...............\cdots&space;Y_{N}\mathit{ln}(\Theta&space;(X_{N}\cdot&space;W))&space;&plus;&space;(1&space;-&space;Y_{N})\mathit{ln}(1-\Theta&space;(X_{N}\cdot&space;W))&space;\\&space;...............=\sum_{i=1}^{N}&space;Y_{i}\mathit{ln}(\Theta&space;(X_{i}\cdot&space;W))&space;&plus;&space;(1&space;-&space;Y_{i})\mathit{ln}(1-\Theta&space;(X_{N}\cdot&space;W))" title="\mathbf{L}(W) = \mathit{ln}(\mathbf{ML}(W)) \\ ...............= \mathit{ln}(\Phi(X_{1}\cdot W)^{Y_{1}}\times (1- \Phi(X_{1}\cdot W))^{1-Y_{1}} \times \cdots\\ ...............\cdots \times \Phi(X_{N}\cdot W)^{Y_{N}}\times (1- \Phi(X_{N}\cdot W))^{1-Y_{N}})\\ \\ ...............= \mathit{ln}(\Phi(X_{1}\cdot W)^{Y_{1}}) + \mathit{ln}((1- \Phi(X_{1}\cdot W))^{1-Y_{1}})+\dots \\ ...............\cdots + \mathit{ln}(\Phi(X_{N}\cdot W)^{Y_{N}}) + \mathit{ln}((1- \Phi(X_{N}\cdot W))^{1-Y_{N}})\\ \\ ...............=Y_{1}\mathit{ln}(\Theta (X_{1}\cdot W)) + (1 - Y_{1})\mathit{ln}(1-\Theta (X_{1}\cdot W))+\cdots \\ ...............\cdots Y_{N}\mathit{ln}(\Theta (X_{N}\cdot W)) + (1 - Y_{N})\mathit{ln}(1-\Theta (X_{N}\cdot W)) \\ ...............=\sum_{i=1}^{N} Y_{i}\mathit{ln}(\Theta (X_{i}\cdot W)) + (1 - Y_{i})\mathit{ln}(1-\Theta (X_{N}\cdot W))" />

计算上式的最大值，也就是计算如下的成本函数的最小值：

<img src="http://latex.codecogs.com/gif.latex?\mathit{cost}&space;=&space;-&space;\frac{1}{N}\mathbf{L}(W)&space;\\" title="\mathit{cost} = - \frac{1}{N}\mathbf{L}(W) \\" />

+ **梯度下降推导**

计算成本函数<a href="http://www.codecogs.com/eqnedit.php?latex=\mathit{cost}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\mathit{cost}" title="\mathit{cost}" /></a>对<a href="http://www.codecogs.com/eqnedit.php?latex=W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?W" title="W" /></a>的梯度：

<a href="http://www.codecogs.com/eqnedit.php?latex=\frac{\partial&space;\mathit{cost}}{\partial&space;W}&space;=&space;-\frac{1}{N}\sum_{i=1}^{N}[(Y_{i}\frac{1}{\Theta&space;(X_{i}\cdot&space;W)}-(1-Y_{i})(\frac{1}{1-\Theta&space;(X_{i}\cdot&space;W)})]\frac{\partial&space;\Theta&space;(X_{i},W)}{\partial&space;W}\\&space;..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}(1-\Theta&space;(X_{i}\cdot&space;W))-(1-Y_{i})\Theta&space;(X_{i}\cdot&space;W)]&space;\frac{\partial&space;(X_{i}\cdot&space;W)}{\partial&space;W}\\&space;..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}-\Theta&space;(X_{i}\cdot&space;W)]X_{i}\\&space;..............=-\frac{1}{N}X^{T}\cdot&space;(Y&space;-&space;\Theta&space;(X,&space;W)\\&space;..............=\frac{1}{N}X^{T}\cdot&space;(\Theta&space;(X,&space;W)-&space;Y)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\frac{\partial&space;\mathit{cost}}{\partial&space;W}&space;=&space;-\frac{1}{N}\sum_{i=1}^{N}[(Y_{i}\frac{1}{\Theta&space;(X_{i}\cdot&space;W)}-(1-Y_{i})(\frac{1}{1-\Theta&space;(X_{i}\cdot&space;W)})]\frac{\partial&space;\Theta&space;(X_{i},W)}{\partial&space;W}\\&space;..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}(1-\Theta&space;(X_{i}\cdot&space;W))-(1-Y_{i})\Theta&space;(X_{i}\cdot&space;W)]&space;\frac{\partial&space;(X_{i}\cdot&space;W)}{\partial&space;W}\\&space;..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}-\Theta&space;(X_{i}\cdot&space;W)]X_{i}\\&space;..............=-\frac{1}{N}X^{T}\cdot&space;(Y&space;-&space;\Theta&space;(X,&space;W)\\&space;..............=\frac{1}{N}X^{T}\cdot&space;(\Theta&space;(X,&space;W)-&space;Y)" title="\frac{\partial \mathit{cost}}{\partial W} = -\frac{1}{N}\sum_{i=1}^{N}[(Y_{i}\frac{1}{\Theta (X_{i}\cdot W)}-(1-Y_{i})(\frac{1}{1-\Theta (X_{i}\cdot W)})]\frac{\partial \Theta (X_{i},W)}{\partial W}\\ ..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}(1-\Theta (X_{i}\cdot W))-(1-Y_{i})\Theta (X_{i}\cdot W)] \frac{\partial (X_{i}\cdot W)}{\partial W}\\ ..............=-\frac{1}{N}\sum_{i=1}^{N}[Y_{i}-\Theta (X_{i}\cdot W)]X_{i}\\ ..............=-\frac{1}{N}X^{T}\cdot (Y - \Theta (X, W)\\ ..............=\frac{1}{N}X^{T}\cdot (\Theta (X, W)- Y)" /></a>

+ **正则化**

<a href="http://www.codecogs.com/eqnedit.php?latex=L2" target="_blank"><img src="http://latex.codecogs.com/gif.latex?L2" title="L2" /></a>正则化，也就是在成本函数<a href="http://www.codecogs.com/eqnedit.php?latex=\mathit{cost}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\mathit{cost}" title="\mathit{cost}" /></a>中加上下式：

<a href="http://www.codecogs.com/eqnedit.php?latex=L2=\frac{\lambda&space;}{2N}\left&space;\|&space;W&space;\right&space;\|^{2}=\frac{\lambda&space;}{2N}W^{T}\cdot&space;W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?L2=\frac{\lambda&space;}{2N}\left&space;\|&space;W&space;\right&space;\|^{2}=\frac{\lambda&space;}{2N}W^{T}\cdot&space;W" title="L2=\frac{\lambda }{2N}\left \| W \right \|^{2}=\frac{\lambda }{2N}W^{T}\cdot W" /></a>

正则化的目的是为了防止过拟合，这由参数<a href="http://www.codecogs.com/eqnedit.php?latex=\lambda" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\lambda" title="\lambda" /></a>的大小决定。添加<a href="http://www.codecogs.com/eqnedit.php?latex=L2" target="_blank"><img src="http://latex.codecogs.com/gif.latex?L2" title="L2" /></a>正则化下的梯度：

<a href="http://www.codecogs.com/eqnedit.php?latex=\frac{\partial&space;\mathit{cost}}{\partial&space;W}=\frac{1}{N}X^{T}\cdot&space;(\Theta&space;(X,&space;W)-&space;Y)&plus;\frac{\lambda&space;}{N}W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\frac{\partial&space;\mathit{cost}}{\partial&space;W}=\frac{1}{N}X^{T}\cdot&space;(\Theta&space;(X,&space;W)-&space;Y)&plus;\frac{\lambda&space;}{N}W" title="\frac{\partial \mathit{cost}}{\partial W}=\frac{1}{N}X^{T}\cdot (\Theta (X, W)- Y)+\frac{\lambda }{N}W" /></a>

更新<a href="http://www.codecogs.com/eqnedit.php?latex=W" target="_blank"><img src="http://latex.codecogs.com/gif.latex?W" title="W" /></a>：

<a href="http://www.codecogs.com/eqnedit.php?latex=\mathbf{W&space;=&space;W&space;-&space;\boldsymbol{\eta&space;\times&space;\frac{\partial&space;\boldsymbol{cost}}{\partial&space;\mathbf{W}}}}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\mathbf{W&space;=&space;W&space;-&space;\boldsymbol{\eta&space;\times&space;\frac{\partial&space;\boldsymbol{cost}}{\partial&space;\mathbf{W}}}}" title="\mathbf{W = W - \boldsymbol{\eta \times \frac{\partial \boldsymbol{cost}}{\partial \mathbf{W}}}}" /></a>

其中<a href="http://www.codecogs.com/eqnedit.php?latex=\eta" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\eta" title="\eta" /></a>表示学习率，可理解为步长。
